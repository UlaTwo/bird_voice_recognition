from torch.utils.data import  Dataset
import torch
import torchaudio
import numpy as np
from torchvision import transforms

class TestDataset(Dataset):
    # Argument list
    # path to the BirdVox-20k csv file
    # path to the BirdVox-20k audio files
    
    def __init__(self, file_path, label):
        self.labels = []
        self.labels.append(label)
            
        self.file_path = file_path
        self.waveform, self.sample_rate = torchaudio.load(self.file_path)
        self.mel_spectogram = torchaudio.transforms.MelSpectrogram(sample_rate=44100,n_fft=1261, n_mels=80, window_fn=torch.hamming_window, f_min=50, f_max = 12000)
        self.amplitude_to_db = torchaudio.transforms.AmplitudeToDB()
        self.resample = torchaudio.transforms.Resample(self.sample_rate, 44100)
        self.resize = transforms.Resize((80,700))
        
    
    def __getitem__(self, index):
        
        waveform = self.resample(self.waveform)
        # utworzenie Mal Spektogramu
        specgram = self.mel_spectogram(waveform)
        specgram  = self.resize(specgram)
        # transformacja za skali amplitud do decybeli
        transformedAmpToDB = self.amplitude_to_db(specgram)
        
        # normalizacja
        tensor_minusmean = transformedAmpToDB - transformedAmpToDB.mean()
        soundFormatted = tensor_minusmean/tensor_minusmean.abs().max()

        #PYTANIE: czy tak jest bardzo nieelegancko?
        #je≈õli nie dam tutaj tego rzutowania na float32, to w cross_entropy jest LongTensor zamiast Float/tensor
        return soundFormatted, np.float32( self.labels[index] )
    
    def __len__(self):
        return len(self.labels)